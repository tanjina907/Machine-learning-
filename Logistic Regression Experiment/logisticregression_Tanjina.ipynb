{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "89bd2b8b",
   "metadata": {},
   "source": [
    "# Logistic Regression Experiement with Data "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8a101fb",
   "metadata": {},
   "source": [
    "# Importing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 488,
   "id": "abc39011",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>y_numeric</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>95</td>\n",
       "      <td>48</td>\n",
       "      <td>83</td>\n",
       "      <td>178</td>\n",
       "      <td>72</td>\n",
       "      <td>10</td>\n",
       "      <td>162</td>\n",
       "      <td>42</td>\n",
       "      <td>20</td>\n",
       "      <td>159</td>\n",
       "      <td>176</td>\n",
       "      <td>379</td>\n",
       "      <td>184</td>\n",
       "      <td>70</td>\n",
       "      <td>6</td>\n",
       "      <td>16</td>\n",
       "      <td>187</td>\n",
       "      <td>197</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>91</td>\n",
       "      <td>41</td>\n",
       "      <td>84</td>\n",
       "      <td>141</td>\n",
       "      <td>57</td>\n",
       "      <td>9</td>\n",
       "      <td>149</td>\n",
       "      <td>45</td>\n",
       "      <td>19</td>\n",
       "      <td>143</td>\n",
       "      <td>170</td>\n",
       "      <td>330</td>\n",
       "      <td>158</td>\n",
       "      <td>72</td>\n",
       "      <td>9</td>\n",
       "      <td>14</td>\n",
       "      <td>189</td>\n",
       "      <td>199</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>104</td>\n",
       "      <td>50</td>\n",
       "      <td>106</td>\n",
       "      <td>209</td>\n",
       "      <td>66</td>\n",
       "      <td>10</td>\n",
       "      <td>207</td>\n",
       "      <td>32</td>\n",
       "      <td>23</td>\n",
       "      <td>158</td>\n",
       "      <td>223</td>\n",
       "      <td>635</td>\n",
       "      <td>220</td>\n",
       "      <td>73</td>\n",
       "      <td>14</td>\n",
       "      <td>9</td>\n",
       "      <td>188</td>\n",
       "      <td>196</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>93</td>\n",
       "      <td>41</td>\n",
       "      <td>82</td>\n",
       "      <td>159</td>\n",
       "      <td>63</td>\n",
       "      <td>9</td>\n",
       "      <td>144</td>\n",
       "      <td>46</td>\n",
       "      <td>19</td>\n",
       "      <td>143</td>\n",
       "      <td>160</td>\n",
       "      <td>309</td>\n",
       "      <td>127</td>\n",
       "      <td>63</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>199</td>\n",
       "      <td>207</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>85</td>\n",
       "      <td>44</td>\n",
       "      <td>70</td>\n",
       "      <td>205</td>\n",
       "      <td>103</td>\n",
       "      <td>52</td>\n",
       "      <td>149</td>\n",
       "      <td>45</td>\n",
       "      <td>19</td>\n",
       "      <td>144</td>\n",
       "      <td>241</td>\n",
       "      <td>325</td>\n",
       "      <td>188</td>\n",
       "      <td>127</td>\n",
       "      <td>9</td>\n",
       "      <td>11</td>\n",
       "      <td>180</td>\n",
       "      <td>183</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>841</th>\n",
       "      <td>93</td>\n",
       "      <td>39</td>\n",
       "      <td>87</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>8</td>\n",
       "      <td>169</td>\n",
       "      <td>40</td>\n",
       "      <td>20</td>\n",
       "      <td>134</td>\n",
       "      <td>200</td>\n",
       "      <td>422</td>\n",
       "      <td>149</td>\n",
       "      <td>72</td>\n",
       "      <td>7</td>\n",
       "      <td>25</td>\n",
       "      <td>188</td>\n",
       "      <td>195</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>842</th>\n",
       "      <td>89</td>\n",
       "      <td>46</td>\n",
       "      <td>84</td>\n",
       "      <td>163</td>\n",
       "      <td>66</td>\n",
       "      <td>11</td>\n",
       "      <td>159</td>\n",
       "      <td>43</td>\n",
       "      <td>20</td>\n",
       "      <td>159</td>\n",
       "      <td>173</td>\n",
       "      <td>368</td>\n",
       "      <td>176</td>\n",
       "      <td>72</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>186</td>\n",
       "      <td>197</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>843</th>\n",
       "      <td>106</td>\n",
       "      <td>54</td>\n",
       "      <td>101</td>\n",
       "      <td>222</td>\n",
       "      <td>67</td>\n",
       "      <td>12</td>\n",
       "      <td>222</td>\n",
       "      <td>30</td>\n",
       "      <td>25</td>\n",
       "      <td>173</td>\n",
       "      <td>228</td>\n",
       "      <td>721</td>\n",
       "      <td>200</td>\n",
       "      <td>70</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>187</td>\n",
       "      <td>201</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>844</th>\n",
       "      <td>86</td>\n",
       "      <td>36</td>\n",
       "      <td>78</td>\n",
       "      <td>146</td>\n",
       "      <td>58</td>\n",
       "      <td>7</td>\n",
       "      <td>135</td>\n",
       "      <td>50</td>\n",
       "      <td>18</td>\n",
       "      <td>124</td>\n",
       "      <td>155</td>\n",
       "      <td>270</td>\n",
       "      <td>148</td>\n",
       "      <td>66</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>190</td>\n",
       "      <td>195</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>845</th>\n",
       "      <td>85</td>\n",
       "      <td>36</td>\n",
       "      <td>66</td>\n",
       "      <td>123</td>\n",
       "      <td>55</td>\n",
       "      <td>5</td>\n",
       "      <td>120</td>\n",
       "      <td>56</td>\n",
       "      <td>17</td>\n",
       "      <td>128</td>\n",
       "      <td>140</td>\n",
       "      <td>212</td>\n",
       "      <td>131</td>\n",
       "      <td>73</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>186</td>\n",
       "      <td>190</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>846 rows × 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       1   2    3    4    5   6    7   8   9   10   11   12   13   14  15  16  \\\n",
       "0     95  48   83  178   72  10  162  42  20  159  176  379  184   70   6  16   \n",
       "1     91  41   84  141   57   9  149  45  19  143  170  330  158   72   9  14   \n",
       "2    104  50  106  209   66  10  207  32  23  158  223  635  220   73  14   9   \n",
       "3     93  41   82  159   63   9  144  46  19  143  160  309  127   63   6  10   \n",
       "4     85  44   70  205  103  52  149  45  19  144  241  325  188  127   9  11   \n",
       "..   ...  ..  ...  ...  ...  ..  ...  ..  ..  ...  ...  ...  ...  ...  ..  ..   \n",
       "841   93  39   87  183   64   8  169  40  20  134  200  422  149   72   7  25   \n",
       "842   89  46   84  163   66  11  159  43  20  159  173  368  176   72   1  20   \n",
       "843  106  54  101  222   67  12  222  30  25  173  228  721  200   70   3   4   \n",
       "844   86  36   78  146   58   7  135  50  18  124  155  270  148   66   0  25   \n",
       "845   85  36   66  123   55   5  120  56  17  128  140  212  131   73   1  18   \n",
       "\n",
       "      17   18  y_numeric  \n",
       "0    187  197          4  \n",
       "1    189  199          4  \n",
       "2    188  196          2  \n",
       "3    199  207          4  \n",
       "4    180  183          3  \n",
       "..   ...  ...        ...  \n",
       "841  188  195          2  \n",
       "842  186  197          4  \n",
       "843  187  201          2  \n",
       "844  190  195          2  \n",
       "845  186  190          4  \n",
       "\n",
       "[846 rows x 19 columns]"
      ]
     },
     "execution_count": 488,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import pandas as pd \n",
    "log_data=pd.read_csv('data.csv')\n",
    "log_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 489,
   "id": "b1b8f49f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13',\n",
       "       '14', '15', '16', '17', '18', 'y_numeric'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 489,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 490,
   "id": "123baf49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(846, 19)"
      ]
     },
     "execution_count": 490,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 491,
   "id": "0ebf4893",
   "metadata": {},
   "outputs": [],
   "source": [
    "X= log_data.iloc[:,[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17]]\n",
    "y= log_data['y_numeric']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56ffa9bf",
   "metadata": {},
   "source": [
    "# Split the Data Model into Train data and Test data \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 492,
   "id": "1db67553",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>y_numeric</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>97</td>\n",
       "      <td>45</td>\n",
       "      <td>88</td>\n",
       "      <td>173</td>\n",
       "      <td>67</td>\n",
       "      <td>10</td>\n",
       "      <td>157</td>\n",
       "      <td>43</td>\n",
       "      <td>20</td>\n",
       "      <td>157</td>\n",
       "      <td>173</td>\n",
       "      <td>365</td>\n",
       "      <td>157</td>\n",
       "      <td>67</td>\n",
       "      <td>8</td>\n",
       "      <td>12</td>\n",
       "      <td>192</td>\n",
       "      <td>200</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>85</td>\n",
       "      <td>43</td>\n",
       "      <td>64</td>\n",
       "      <td>128</td>\n",
       "      <td>56</td>\n",
       "      <td>8</td>\n",
       "      <td>150</td>\n",
       "      <td>46</td>\n",
       "      <td>19</td>\n",
       "      <td>144</td>\n",
       "      <td>168</td>\n",
       "      <td>324</td>\n",
       "      <td>173</td>\n",
       "      <td>82</td>\n",
       "      <td>9</td>\n",
       "      <td>14</td>\n",
       "      <td>180</td>\n",
       "      <td>184</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>718</th>\n",
       "      <td>104</td>\n",
       "      <td>52</td>\n",
       "      <td>110</td>\n",
       "      <td>172</td>\n",
       "      <td>53</td>\n",
       "      <td>10</td>\n",
       "      <td>219</td>\n",
       "      <td>30</td>\n",
       "      <td>25</td>\n",
       "      <td>166</td>\n",
       "      <td>235</td>\n",
       "      <td>711</td>\n",
       "      <td>218</td>\n",
       "      <td>74</td>\n",
       "      <td>10</td>\n",
       "      <td>28</td>\n",
       "      <td>188</td>\n",
       "      <td>198</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>482</th>\n",
       "      <td>94</td>\n",
       "      <td>46</td>\n",
       "      <td>79</td>\n",
       "      <td>181</td>\n",
       "      <td>62</td>\n",
       "      <td>8</td>\n",
       "      <td>167</td>\n",
       "      <td>40</td>\n",
       "      <td>20</td>\n",
       "      <td>148</td>\n",
       "      <td>190</td>\n",
       "      <td>418</td>\n",
       "      <td>193</td>\n",
       "      <td>67</td>\n",
       "      <td>12</td>\n",
       "      <td>15</td>\n",
       "      <td>191</td>\n",
       "      <td>198</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>563</th>\n",
       "      <td>89</td>\n",
       "      <td>42</td>\n",
       "      <td>75</td>\n",
       "      <td>140</td>\n",
       "      <td>55</td>\n",
       "      <td>6</td>\n",
       "      <td>145</td>\n",
       "      <td>46</td>\n",
       "      <td>19</td>\n",
       "      <td>139</td>\n",
       "      <td>170</td>\n",
       "      <td>312</td>\n",
       "      <td>166</td>\n",
       "      <td>71</td>\n",
       "      <td>15</td>\n",
       "      <td>26</td>\n",
       "      <td>191</td>\n",
       "      <td>198</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       1   2    3    4   5   6    7   8   9   10   11   12   13  14  15  16  \\\n",
       "128   97  45   88  173  67  10  157  43  20  157  173  365  157  67   8  12   \n",
       "118   85  43   64  128  56   8  150  46  19  144  168  324  173  82   9  14   \n",
       "718  104  52  110  172  53  10  219  30  25  166  235  711  218  74  10  28   \n",
       "482   94  46   79  181  62   8  167  40  20  148  190  418  193  67  12  15   \n",
       "563   89  42   75  140  55   6  145  46  19  139  170  312  166  71  15  26   \n",
       "\n",
       "      17   18  y_numeric  \n",
       "128  192  200          4  \n",
       "118  180  184          3  \n",
       "718  188  198          1  \n",
       "482  191  198          1  \n",
       "563  191  198          1  "
      ]
     },
     "execution_count": 492,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "#train,test =train_test_split(log_data, stratify=log_data[\"y_numeric\"], train_size=0.5)\n",
    "train.head()\n",
    "X_train,X_test, y_train, y_test =train_test_split(X,y, test_size= 0.2)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3104bdb2",
   "metadata": {},
   "source": [
    "# Fit the data into logistic Regression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 493,
   "id": "c557c597",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-85 {color: black;background-color: white;}#sk-container-id-85 pre{padding: 0;}#sk-container-id-85 div.sk-toggleable {background-color: white;}#sk-container-id-85 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-85 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-85 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-85 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-85 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-85 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-85 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-85 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-85 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-85 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-85 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-85 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-85 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-85 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-85 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-85 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-85 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-85 div.sk-item {position: relative;z-index: 1;}#sk-container-id-85 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-85 div.sk-item::before, #sk-container-id-85 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-85 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-85 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-85 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-85 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-85 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-85 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-85 div.sk-label-container {text-align: center;}#sk-container-id-85 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-85 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-85\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(max_iter=6000)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-101\" type=\"checkbox\" checked><label for=\"sk-estimator-id-101\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(max_iter=6000)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(max_iter=6000)"
      ]
     },
     "execution_count": 493,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "lr= LogisticRegression(max_iter=6000\n",
    "                      )\n",
    "\n",
    "lr.fit(X_train,y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 494,
   "id": "d594ac12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>676</th>\n",
       "      <td>82</td>\n",
       "      <td>43</td>\n",
       "      <td>73</td>\n",
       "      <td>158</td>\n",
       "      <td>68</td>\n",
       "      <td>7</td>\n",
       "      <td>151</td>\n",
       "      <td>44</td>\n",
       "      <td>19</td>\n",
       "      <td>145</td>\n",
       "      <td>181</td>\n",
       "      <td>337</td>\n",
       "      <td>173</td>\n",
       "      <td>80</td>\n",
       "      <td>2</td>\n",
       "      <td>17</td>\n",
       "      <td>183</td>\n",
       "      <td>188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>359</th>\n",
       "      <td>100</td>\n",
       "      <td>49</td>\n",
       "      <td>96</td>\n",
       "      <td>206</td>\n",
       "      <td>63</td>\n",
       "      <td>9</td>\n",
       "      <td>186</td>\n",
       "      <td>35</td>\n",
       "      <td>22</td>\n",
       "      <td>156</td>\n",
       "      <td>202</td>\n",
       "      <td>519</td>\n",
       "      <td>176</td>\n",
       "      <td>62</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>197</td>\n",
       "      <td>205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>831</th>\n",
       "      <td>100</td>\n",
       "      <td>47</td>\n",
       "      <td>70</td>\n",
       "      <td>185</td>\n",
       "      <td>70</td>\n",
       "      <td>7</td>\n",
       "      <td>162</td>\n",
       "      <td>40</td>\n",
       "      <td>20</td>\n",
       "      <td>153</td>\n",
       "      <td>179</td>\n",
       "      <td>406</td>\n",
       "      <td>172</td>\n",
       "      <td>68</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>200</td>\n",
       "      <td>205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>653</th>\n",
       "      <td>97</td>\n",
       "      <td>41</td>\n",
       "      <td>92</td>\n",
       "      <td>197</td>\n",
       "      <td>63</td>\n",
       "      <td>10</td>\n",
       "      <td>179</td>\n",
       "      <td>37</td>\n",
       "      <td>21</td>\n",
       "      <td>140</td>\n",
       "      <td>197</td>\n",
       "      <td>481</td>\n",
       "      <td>136</td>\n",
       "      <td>63</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>197</td>\n",
       "      <td>204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>512</th>\n",
       "      <td>103</td>\n",
       "      <td>54</td>\n",
       "      <td>107</td>\n",
       "      <td>189</td>\n",
       "      <td>56</td>\n",
       "      <td>11</td>\n",
       "      <td>223</td>\n",
       "      <td>30</td>\n",
       "      <td>25</td>\n",
       "      <td>174</td>\n",
       "      <td>225</td>\n",
       "      <td>729</td>\n",
       "      <td>200</td>\n",
       "      <td>70</td>\n",
       "      <td>0</td>\n",
       "      <td>29</td>\n",
       "      <td>187</td>\n",
       "      <td>201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>800</th>\n",
       "      <td>88</td>\n",
       "      <td>41</td>\n",
       "      <td>80</td>\n",
       "      <td>147</td>\n",
       "      <td>62</td>\n",
       "      <td>8</td>\n",
       "      <td>146</td>\n",
       "      <td>45</td>\n",
       "      <td>19</td>\n",
       "      <td>144</td>\n",
       "      <td>169</td>\n",
       "      <td>318</td>\n",
       "      <td>161</td>\n",
       "      <td>71</td>\n",
       "      <td>4</td>\n",
       "      <td>16</td>\n",
       "      <td>188</td>\n",
       "      <td>197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>370</th>\n",
       "      <td>96</td>\n",
       "      <td>41</td>\n",
       "      <td>77</td>\n",
       "      <td>177</td>\n",
       "      <td>64</td>\n",
       "      <td>5</td>\n",
       "      <td>177</td>\n",
       "      <td>36</td>\n",
       "      <td>21</td>\n",
       "      <td>134</td>\n",
       "      <td>205</td>\n",
       "      <td>485</td>\n",
       "      <td>148</td>\n",
       "      <td>74</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>196</td>\n",
       "      <td>198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>88</td>\n",
       "      <td>35</td>\n",
       "      <td>50</td>\n",
       "      <td>121</td>\n",
       "      <td>58</td>\n",
       "      <td>5</td>\n",
       "      <td>114</td>\n",
       "      <td>59</td>\n",
       "      <td>17</td>\n",
       "      <td>122</td>\n",
       "      <td>132</td>\n",
       "      <td>192</td>\n",
       "      <td>138</td>\n",
       "      <td>74</td>\n",
       "      <td>21</td>\n",
       "      <td>4</td>\n",
       "      <td>182</td>\n",
       "      <td>187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>488</th>\n",
       "      <td>82</td>\n",
       "      <td>39</td>\n",
       "      <td>86</td>\n",
       "      <td>140</td>\n",
       "      <td>54</td>\n",
       "      <td>7</td>\n",
       "      <td>153</td>\n",
       "      <td>45</td>\n",
       "      <td>19</td>\n",
       "      <td>134</td>\n",
       "      <td>174</td>\n",
       "      <td>338</td>\n",
       "      <td>139</td>\n",
       "      <td>71</td>\n",
       "      <td>11</td>\n",
       "      <td>18</td>\n",
       "      <td>183</td>\n",
       "      <td>189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>718</th>\n",
       "      <td>104</td>\n",
       "      <td>52</td>\n",
       "      <td>110</td>\n",
       "      <td>172</td>\n",
       "      <td>53</td>\n",
       "      <td>10</td>\n",
       "      <td>219</td>\n",
       "      <td>30</td>\n",
       "      <td>25</td>\n",
       "      <td>166</td>\n",
       "      <td>235</td>\n",
       "      <td>711</td>\n",
       "      <td>218</td>\n",
       "      <td>74</td>\n",
       "      <td>10</td>\n",
       "      <td>28</td>\n",
       "      <td>188</td>\n",
       "      <td>198</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>676 rows × 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       1   2    3    4   5   6    7   8   9   10   11   12   13  14  15  16  \\\n",
       "676   82  43   73  158  68   7  151  44  19  145  181  337  173  80   2  17   \n",
       "359  100  49   96  206  63   9  186  35  22  156  202  519  176  62   3   5   \n",
       "831  100  47   70  185  70   7  162  40  20  153  179  406  172  68   9   6   \n",
       "653   97  41   92  197  63  10  179  37  21  140  197  481  136  63   4   3   \n",
       "512  103  54  107  189  56  11  223  30  25  174  225  729  200  70   0  29   \n",
       "..   ...  ..  ...  ...  ..  ..  ...  ..  ..  ...  ...  ...  ...  ..  ..  ..   \n",
       "800   88  41   80  147  62   8  146  45  19  144  169  318  161  71   4  16   \n",
       "370   96  41   77  177  64   5  177  36  21  134  205  485  148  74   0   4   \n",
       "113   88  35   50  121  58   5  114  59  17  122  132  192  138  74  21   4   \n",
       "488   82  39   86  140  54   7  153  45  19  134  174  338  139  71  11  18   \n",
       "718  104  52  110  172  53  10  219  30  25  166  235  711  218  74  10  28   \n",
       "\n",
       "      17   18  \n",
       "676  183  188  \n",
       "359  197  205  \n",
       "831  200  205  \n",
       "653  197  204  \n",
       "512  187  201  \n",
       "..   ...  ...  \n",
       "800  188  197  \n",
       "370  196  198  \n",
       "113  182  187  \n",
       "488  183  189  \n",
       "718  188  198  \n",
       "\n",
       "[676 rows x 18 columns]"
      ]
     },
     "execution_count": 494,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 495,
   "id": "08001a1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "676    3\n",
       "359    1\n",
       "831    3\n",
       "653    1\n",
       "512    1\n",
       "      ..\n",
       "800    4\n",
       "370    3\n",
       "113    1\n",
       "488    1\n",
       "718    1\n",
       "Name: y_numeric, Length: 676, dtype: int64"
      ]
     },
     "execution_count": 495,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 496,
   "id": "513c1448",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "170"
      ]
     },
     "execution_count": 496,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 497,
   "id": "c071eb95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 2, 1, 2, 3, 2, 2, 1, 4, 3, 3, 3, 4, 3, 2, 1, 3, 3, 4, 2, 1, 3,\n",
       "       2, 1, 4, 1, 1, 1, 4, 4, 1, 4, 4, 1, 3, 2, 3, 2, 2, 4, 4, 1, 3, 4,\n",
       "       3, 2, 3, 1, 3, 1, 3, 2, 3, 3, 4, 3, 4, 1, 2, 3, 4, 1, 1, 3, 3, 1,\n",
       "       3, 2, 3, 1, 1, 2, 4, 4, 3, 2, 3, 3, 2, 1, 4, 4, 1, 3, 3, 1, 4, 4,\n",
       "       3, 4, 2, 4, 1, 3, 1, 4, 1, 4, 3, 2, 4, 3, 1, 4, 2, 4, 3, 4, 4, 3,\n",
       "       4, 4, 4, 1, 2, 1, 3, 3, 3, 1, 4, 3, 3, 3, 1, 3, 3, 1, 4, 4, 3, 2,\n",
       "       1, 4, 1, 3, 2, 1, 2, 3, 2, 4, 4, 2, 1, 2, 3, 1, 3, 3, 1, 2, 3, 3,\n",
       "       1, 1, 1, 3, 1, 3, 2, 3, 1, 4, 4, 3, 2, 1, 2, 4])"
      ]
     },
     "execution_count": 497,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4998ff5e",
   "metadata": {},
   "source": [
    "# Predict the data using Logistic Regression OVR Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 502,
   "id": "bb64dad9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>613</th>\n",
       "      <td>92</td>\n",
       "      <td>37</td>\n",
       "      <td>75</td>\n",
       "      <td>191</td>\n",
       "      <td>71</td>\n",
       "      <td>6</td>\n",
       "      <td>161</td>\n",
       "      <td>40</td>\n",
       "      <td>20</td>\n",
       "      <td>128</td>\n",
       "      <td>180</td>\n",
       "      <td>393</td>\n",
       "      <td>135</td>\n",
       "      <td>69</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>195</td>\n",
       "      <td>202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289</th>\n",
       "      <td>88</td>\n",
       "      <td>37</td>\n",
       "      <td>57</td>\n",
       "      <td>132</td>\n",
       "      <td>62</td>\n",
       "      <td>6</td>\n",
       "      <td>135</td>\n",
       "      <td>50</td>\n",
       "      <td>18</td>\n",
       "      <td>125</td>\n",
       "      <td>151</td>\n",
       "      <td>265</td>\n",
       "      <td>144</td>\n",
       "      <td>83</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>180</td>\n",
       "      <td>184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>95</td>\n",
       "      <td>48</td>\n",
       "      <td>104</td>\n",
       "      <td>214</td>\n",
       "      <td>67</td>\n",
       "      <td>9</td>\n",
       "      <td>205</td>\n",
       "      <td>32</td>\n",
       "      <td>23</td>\n",
       "      <td>151</td>\n",
       "      <td>227</td>\n",
       "      <td>628</td>\n",
       "      <td>202</td>\n",
       "      <td>74</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>186</td>\n",
       "      <td>193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>788</th>\n",
       "      <td>115</td>\n",
       "      <td>52</td>\n",
       "      <td>100</td>\n",
       "      <td>203</td>\n",
       "      <td>62</td>\n",
       "      <td>10</td>\n",
       "      <td>217</td>\n",
       "      <td>31</td>\n",
       "      <td>24</td>\n",
       "      <td>165</td>\n",
       "      <td>229</td>\n",
       "      <td>697</td>\n",
       "      <td>214</td>\n",
       "      <td>72</td>\n",
       "      <td>14</td>\n",
       "      <td>4</td>\n",
       "      <td>188</td>\n",
       "      <td>197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>98</td>\n",
       "      <td>49</td>\n",
       "      <td>84</td>\n",
       "      <td>219</td>\n",
       "      <td>74</td>\n",
       "      <td>7</td>\n",
       "      <td>190</td>\n",
       "      <td>34</td>\n",
       "      <td>22</td>\n",
       "      <td>154</td>\n",
       "      <td>208</td>\n",
       "      <td>558</td>\n",
       "      <td>209</td>\n",
       "      <td>74</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>195</td>\n",
       "      <td>195</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       1   2    3    4   5   6    7   8   9   10   11   12   13  14  15  16  \\\n",
       "613   92  37   75  191  71   6  161  40  20  128  180  393  135  69   1  14   \n",
       "289   88  37   57  132  62   6  135  50  18  125  151  265  144  83  16  16   \n",
       "40    95  48  104  214  67   9  205  32  23  151  227  628  202  74   5   9   \n",
       "788  115  52  100  203  62  10  217  31  24  165  229  697  214  72  14   4   \n",
       "69    98  49   84  219  74   7  190  34  22  154  208  558  209  74   4   7   \n",
       "\n",
       "      17   18  \n",
       "613  195  202  \n",
       "289  180  184  \n",
       "40   186  193  \n",
       "788  188  197  \n",
       "69   195  195  "
      ]
     },
     "execution_count": 502,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.copy()\n",
    "lr.predict(X_test)\n",
    "X_test.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 503,
   "id": "67fda1a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 504,
   "id": "53a4d485",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8224852071005917\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(lr.score(X_train,y_train))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 505,
   "id": "965dc58e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[-0.22749861,  0.37034253, -0.06503509,  0.25940309, -0.72064249,\n",
       "         -0.23681168,  0.74885074,  0.99973126,  0.10947612, -0.36108951,\n",
       "         -0.13344382, -0.06177282,  0.02540629, -0.23651742,  0.03106247,\n",
       "         -0.00519531, -0.02555284, -0.15665699],\n",
       "        [-0.02535142, -0.1737847 , -0.04519569,  0.27186779, -0.70335886,\n",
       "         -0.40553001,  0.74515156,  0.73507194,  0.72729947, -0.27469269,\n",
       "         -0.16301335, -0.08887801,  0.07928009, -0.16136693,  0.04266583,\n",
       "         -0.03450217, -0.50794788,  0.26258369],\n",
       "        [-0.14767784, -0.25630935, -0.22752741, -0.37303845,  1.14609404,\n",
       "          0.00507447, -0.43192012, -1.15333718, -0.12073199,  0.01659936,\n",
       "          0.27840018,  0.07296997,  0.03762731, -0.03240748, -0.16265103,\n",
       "          0.1278257 ,  1.3312115 , -0.93564951],\n",
       "        [ 0.40052787,  0.05975152,  0.33775819, -0.15823243,  0.27790732,\n",
       "          0.63726722, -1.06208218, -0.58146603, -0.7160436 ,  0.61918284,\n",
       "          0.01805699,  0.07768087, -0.14231369,  0.43029184,  0.08892273,\n",
       "         -0.08812821, -0.79771079,  0.82972281]]),\n",
       " array([ 0.02732369,  0.01647171, -0.0179958 , -0.02579961]))"
      ]
     },
     "execution_count": 505,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.coef_,lr.intercept_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 506,
   "id": "7fcf67f2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2 : 58.02682235397684\n",
      "0.4 : 58.02742324711523\n",
      "0.6000000000000001 : 58.028016246420535\n",
      "0.8 : 58.02860147644806\n",
      "1.0 : 58.029179058939626\n",
      "1.2000000000000002 : 58.02974911290225\n",
      "1.4000000000000001 : 58.030311754681065\n",
      "1.6 : 58.030867098033376\n",
      "1.8 : 58.031415254196325\n",
      "2.0 : 58.03195633195649\n",
      "2.2 : 58.03249043771488\n",
      "2.4000000000000004 : 58.03301767555019\n",
      "2.6 : 58.03353814728067\n",
      "2.8000000000000003 : 58.034051952524315\n",
      "3.0 : 58.034559188755786\n",
      "3.2 : 58.035059951363834\n",
      "3.4000000000000004 : 58.03555433370469\n"
     ]
    }
   ],
   "source": [
    "# Implementing Ridge Regression Model\n",
    "from statistics import mean\n",
    "from sklearn.linear_model import Ridge\n",
    "# List to maintain the different cross-validation scores\n",
    "cross_val_scores_ridge = []\n",
    "\n",
    "# List to maintain the different values of alpha\n",
    "alpha = []\n",
    "\n",
    "# Loop to compute the different values of cross-validation scores\n",
    "for i in range(1, 18):\n",
    "\tridgeModel = Ridge(alpha = i * 0.2)\n",
    "\tridgeModel.fit(X_train, y_train)\n",
    "\tscores = cross_val_score(ridgeModel, X_train, y_train, cv = 10)\n",
    "\tavg_cross_val_score = mean(scores)*100\n",
    "\tcross_val_scores_ridge.append(avg_cross_val_score)\n",
    "\talpha.append(i * 0.2)\n",
    "\n",
    "# Loop to print the different values of cross-validation scores\n",
    "for i in range(0, len(alpha)):\n",
    "\tprint(str(alpha[i])+' : '+str(cross_val_scores_ridge[i]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d54707c8",
   "metadata": {},
   "source": [
    "# Building and fitting the Ridge Regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 507,
   "id": "4dbd83f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-86 {color: black;background-color: white;}#sk-container-id-86 pre{padding: 0;}#sk-container-id-86 div.sk-toggleable {background-color: white;}#sk-container-id-86 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-86 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-86 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-86 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-86 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-86 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-86 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-86 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-86 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-86 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-86 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-86 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-86 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-86 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-86 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-86 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-86 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-86 div.sk-item {position: relative;z-index: 1;}#sk-container-id-86 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-86 div.sk-item::before, #sk-container-id-86 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-86 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-86 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-86 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-86 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-86 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-86 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-86 div.sk-label-container {text-align: center;}#sk-container-id-86 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-86 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-86\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Ridge(alpha=3.4)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-102\" type=\"checkbox\" checked><label for=\"sk-estimator-id-102\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Ridge</label><div class=\"sk-toggleable__content\"><pre>Ridge(alpha=3.4)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "Ridge(alpha=3.4)"
      ]
     },
     "execution_count": 507,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "ridge_model = Ridge(alpha = 3.4)\n",
    "ridge_model.fit(X_train, y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 513,
   "id": "53ee1859",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.24005731, 2.41624674, 1.17120882, 2.26286077, 2.48822382,\n",
       "       2.17820372, 1.64720689, 1.64326938, 4.33070762, 2.49568338,\n",
       "       2.98559411, 2.88943188, 6.29301714, 3.1110972 , 1.69113688,\n",
       "       1.47099249, 2.45691236, 2.39282838, 3.56107239, 1.83956813,\n",
       "       1.61206679, 2.11107946, 1.83481515, 1.24921386, 3.419074  ,\n",
       "       1.59021234, 2.39403639, 1.68002522, 3.88151766, 3.9606571 ,\n",
       "       1.80580691, 4.22698454, 3.63623005, 1.26757004, 2.7617775 ,\n",
       "       1.13531518, 2.54454135, 3.31673198, 1.32207128, 4.32631479,\n",
       "       3.67449354, 1.97349367, 2.23628788, 3.48616471, 3.31115717,\n",
       "       2.146594  , 2.67793744, 2.18997313, 3.31724296, 0.7142663 ,\n",
       "       2.35317862, 1.20088359, 2.83548611, 3.33576944, 2.86564525,\n",
       "       2.19021485, 3.23479932, 1.62913224, 1.88279779, 2.536705  ,\n",
       "       3.58705901, 1.76053919, 1.39319399, 3.08577818, 3.14568215,\n",
       "       1.6327424 , 2.7132188 , 1.93671804, 2.12212069, 1.96026843,\n",
       "       2.04735919, 1.91272311, 3.47108329, 3.5384512 , 3.29131407,\n",
       "       1.98153515, 2.0509345 , 3.29720477, 1.90955039, 1.08892121,\n",
       "       3.64536297, 3.70918728, 2.96738111, 2.83708424, 3.11511498,\n",
       "       1.13119979, 2.88857958, 8.45109361, 2.71466148, 3.51558462,\n",
       "       2.16326338, 3.34662745, 2.52497636, 2.8562122 , 2.31221917,\n",
       "       3.82993001, 1.25256392, 3.59714233, 2.18522594, 2.39169173,\n",
       "       3.08509626, 2.62157273, 1.23996476, 3.32849732, 1.59386797,\n",
       "       3.15159938, 2.19148752, 4.23746719, 3.56882988, 2.04977803,\n",
       "       3.90370134, 3.42612438, 3.52949577, 2.15959168, 1.70926371,\n",
       "       1.28276835, 2.74038852, 3.04845773, 2.86139082, 1.78135872,\n",
       "       3.88227652, 3.17374239, 2.59689934, 2.05168572, 0.64254982,\n",
       "       3.22146689, 3.50158546, 2.60669882, 3.21672653, 3.79099864,\n",
       "       2.87098852, 2.01060425, 0.66036092, 3.48500587, 2.87493617,\n",
       "       2.63919661, 1.17882586, 2.53325399, 1.98634532, 6.05686956,\n",
       "       1.49875623, 3.10759293, 3.52286939, 2.04988424, 2.3788945 ,\n",
       "       1.44593373, 2.49052077, 1.30783439, 2.94915259, 3.42530692,\n",
       "       2.59699325, 1.68231721, 2.30877937, 2.70568103, 1.92796413,\n",
       "       1.31127856, 0.97316713, 2.68059632, 1.64891883, 3.03337118,\n",
       "       1.3617663 , 2.91199371, 1.01179501, 3.10866237, 3.81128682,\n",
       "       2.37954296, 2.1852687 , 1.05147917, 1.73543301, 3.11495888])"
      ]
     },
     "execution_count": 513,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ridge_model.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 523,
   "id": "638df122",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method RegressorMixin.score of Ridge(alpha=3.4)>"
      ]
     },
     "execution_count": 523,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ridge_model.score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e466b1cb",
   "metadata": {},
   "source": [
    "# Implementing Linear Support Vector Classification Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 534,
   "id": "a253a782",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tanjinaalam/opt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-91 {color: black;background-color: white;}#sk-container-id-91 pre{padding: 0;}#sk-container-id-91 div.sk-toggleable {background-color: white;}#sk-container-id-91 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-91 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-91 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-91 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-91 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-91 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-91 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-91 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-91 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-91 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-91 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-91 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-91 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-91 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-91 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-91 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-91 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-91 div.sk-item {position: relative;z-index: 1;}#sk-container-id-91 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-91 div.sk-item::before, #sk-container-id-91 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-91 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-91 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-91 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-91 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-91 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-91 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-91 div.sk-label-container {text-align: center;}#sk-container-id-91 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-91 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-91\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;standardscaler&#x27;, StandardScaler()),\n",
       "                (&#x27;linearsvc&#x27;, LinearSVC(random_state=0, tol=1e-10))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-115\" type=\"checkbox\" ><label for=\"sk-estimator-id-115\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;standardscaler&#x27;, StandardScaler()),\n",
       "                (&#x27;linearsvc&#x27;, LinearSVC(random_state=0, tol=1e-10))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-116\" type=\"checkbox\" ><label for=\"sk-estimator-id-116\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-117\" type=\"checkbox\" ><label for=\"sk-estimator-id-117\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearSVC</label><div class=\"sk-toggleable__content\"><pre>LinearSVC(random_state=0, tol=1e-10)</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('standardscaler', StandardScaler()),\n",
       "                ('linearsvc', LinearSVC(random_state=0, tol=1e-10))])"
      ]
     },
     "execution_count": 534,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.datasets import make_classification\n",
    "\n",
    "clf = make_pipeline(StandardScaler(),LinearSVC(random_state=0, tol=1e-10))\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 510,
   "id": "2c1633da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.6434164   0.86688869 -0.22881597  1.24283209 -0.88768387  0.11102443\n",
      "   0.78793518  0.16161683 -0.3169033  -0.46903775 -0.61993666  0.41438078\n",
      "  -0.46311637 -0.45839434  0.10702768  0.0337161  -0.19825882 -0.25073077]\n",
      " [ 0.35985602 -0.59582674 -0.27476986  1.34200277 -0.82416801 -0.42928815\n",
      "   0.27716677 -0.45842339  0.75643529 -0.36217735 -0.55475599 -1.33057573\n",
      "   0.59038639 -0.27366716  0.11058386 -0.04913882 -1.25843458  0.87186984]\n",
      " [-0.26461557  0.24171136 -0.72079079 -3.2734092   2.02556837 -0.3974685\n",
      "   0.33580326 -2.14158322 -0.7128445   0.04969376  0.79133271  0.42765956\n",
      "   0.02737404  0.02152432 -0.22168946  0.23775216  1.91615589 -1.51020873]\n",
      " [ 1.05535451 -0.29664324  1.24316946 -1.76032051  0.75188531 -0.25320285\n",
      "  -1.04316583  0.78596774 -1.29984471  2.40767648 -0.01147929 -0.45315429\n",
      "  -1.00576616  0.63744033 -0.01887632 -0.29716248 -1.01938172  1.6858531 ]]\n"
     ]
    }
   ],
   "source": [
    "print(clf.named_steps['linearsvc'].coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 511,
   "id": "1a016d76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.57713953 -0.6116912  -1.0209805  -2.0226153 ]\n"
     ]
    }
   ],
   "source": [
    "print(clf.named_steps['linearsvc'].intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 512,
   "id": "790eedcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3 3 1 2 3 2 2 1 4 3 3 3 4 3 1 1 3 3 4 2 1 3 2 1 4 2 1 1 4 4 1 4 4 1 3 2 3\n",
      " 4 2 4 4 1 3 4 3 2 3 1 3 1 3 2 3 3 4 3 4 1 2 3 4 1 2 3 3 1 3 2 3 1 2 1 4 4\n",
      " 3 2 3 3 2 1 4 4 2 3 3 1 4 4 3 4 2 4 4 3 1 4 1 4 3 2 4 3 1 4 2 4 3 4 4 3 4\n",
      " 4 4 2 2 1 3 3 3 1 4 3 3 3 1 3 3 1 4 4 3 2 1 4 4 3 2 1 2 3 2 4 4 2 1 2 3 1\n",
      " 3 3 3 2 3 3 1 1 2 3 1 3 2 3 1 4 4 3 2 1 2 4]\n"
     ]
    }
   ],
   "source": [
    "print(clf.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 524,
   "id": "f8d776e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tanjinaalam/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py:443: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8224852071005917"
      ]
     },
     "execution_count": 524,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "963f4b87",
   "metadata": {},
   "source": [
    "# implementing C-Support Vector Classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 525,
   "id": "4893bcec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-90 {color: black;background-color: white;}#sk-container-id-90 pre{padding: 0;}#sk-container-id-90 div.sk-toggleable {background-color: white;}#sk-container-id-90 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-90 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-90 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-90 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-90 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-90 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-90 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-90 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-90 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-90 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-90 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-90 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-90 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-90 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-90 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-90 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-90 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-90 div.sk-item {position: relative;z-index: 1;}#sk-container-id-90 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-90 div.sk-item::before, #sk-container-id-90 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-90 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-90 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-90 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-90 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-90 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-90 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-90 div.sk-label-container {text-align: center;}#sk-container-id-90 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-90 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-90\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;standardscaler&#x27;, StandardScaler()),\n",
       "                (&#x27;svc&#x27;, SVC(gamma=&#x27;auto&#x27;))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-112\" type=\"checkbox\" ><label for=\"sk-estimator-id-112\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;standardscaler&#x27;, StandardScaler()),\n",
       "                (&#x27;svc&#x27;, SVC(gamma=&#x27;auto&#x27;))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-113\" type=\"checkbox\" ><label for=\"sk-estimator-id-113\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-114\" type=\"checkbox\" ><label for=\"sk-estimator-id-114\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(gamma=&#x27;auto&#x27;)</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('standardscaler', StandardScaler()),\n",
       "                ('svc', SVC(gamma='auto'))])"
      ]
     },
     "execution_count": 525,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import numpy as np\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "X = np.array(X_train)\n",
    "y = np.array(y_train)\n",
    "from sklearn.svm import SVC\n",
    "SVC_model= make_pipeline(StandardScaler(), SVC(gamma='auto'))\n",
    "SVC_model.fit(X, y)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 541,
   "id": "1680b170",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tanjinaalam/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py:443: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([3, 2, 1, 2, 3, 1, 2, 1, 4, 3, 3, 3, 4, 3, 2, 1, 4, 3, 4, 2, 2, 3,\n",
       "       2, 1, 4, 2, 1, 2, 4, 4, 2, 4, 4, 1, 3, 2, 3, 4, 2, 4, 4, 1, 3, 4,\n",
       "       3, 2, 3, 1, 3, 2, 3, 2, 3, 3, 4, 3, 4, 1, 2, 3, 4, 1, 2, 3, 3, 1,\n",
       "       3, 2, 2, 1, 1, 1, 4, 4, 3, 2, 3, 3, 2, 1, 4, 4, 4, 4, 3, 2, 4, 1,\n",
       "       3, 4, 2, 4, 1, 3, 2, 4, 2, 4, 3, 2, 4, 3, 1, 4, 2, 4, 3, 4, 4, 3,\n",
       "       4, 4, 4, 2, 2, 2, 3, 3, 3, 2, 4, 3, 3, 3, 2, 4, 3, 1, 4, 4, 3, 2,\n",
       "       2, 4, 4, 3, 2, 1, 2, 4, 2, 4, 4, 2, 1, 2, 3, 1, 3, 3, 1, 2, 3, 3,\n",
       "       2, 1, 2, 3, 2, 3, 2, 3, 2, 4, 4, 3, 1, 2, 2, 4])"
      ]
     },
     "execution_count": 541,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SVC_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 529,
   "id": "ffbc926d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8224852071005917"
      ]
     },
     "execution_count": 529,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SVC_model.score(X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8102ec52",
   "metadata": {},
   "source": [
    "# Comparing and Visualizing the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 539,
   "id": "9bed3248",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic(OVR)Regression : 0.8588235294117647\n",
      "Ridge_Regression : 0.5331610091170258\n",
      "Liniear SVC : 0.8705882352941177\n",
      "SVM SVC  : 0.8224852071005917\n"
     ]
    }
   ],
   "source": [
    "\n",
    "models = ['Logistic(OVR)Regression', 'Ridge Regression', 'Liniear SVC', 'SVM SVC ']\n",
    "scores = [lr.score(X_test, y_test),\n",
    "         ridge_model.score(X_test, y_test),\n",
    "         clf.score(X_test, y_test),\n",
    "         SVC_model.score(X,y)]\n",
    " \n",
    "# Building the dictionary to compare the scores\n",
    "mapping = {}\n",
    "mapping['Logistic(OVR)Regression'] = lr.score(X_test, y_test)\n",
    "mapping['Ridge_Regression'] = ridge_model.score(X_test, y_test)\n",
    "mapping['Liniear SVC'] = clf.score(X_test, y_test)\n",
    "mapping['SVM SVC ']= SVC_model.score(X,y)\n",
    " \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c4bd261",
   "metadata": {},
   "source": [
    "# Printing the scores for different models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 542,
   "id": "0f6aaae1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic(OVR)Regression : 0.8588235294117647\n",
      "Ridge_Regression : 0.5331610091170258\n",
      "Liniear SVC : 0.8705882352941177\n",
      "SVM SVC  : 0.8224852071005917\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for key, val in mapping.items():\n",
    "print(str(key)+' : '+str(val))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e926e4fd",
   "metadata": {},
   "source": [
    "# Plotting the scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 540,
   "id": "75266ee6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.bar(models, scores)\n",
    "plt.xlabel(' Models')\n",
    "plt.ylabel('Score')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a858db8",
   "metadata": {},
   "source": [
    "# Observation "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7489cc69",
   "metadata": {},
   "source": [
    "\n",
    "Aftter comparing the score values It is visible that Logistic Regression (OVR, Linear SVC model and SVM SVC model has closer score values, on the other hand L2 regularization/ Ridge model has not closer score value to others."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
